<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on FuWei</title>
    <link>https://fuweid.com/post/</link>
    <description>Recent content in Posts on FuWei</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Sun, 12 Jun 2022 12:00:53 +0800</lastBuildDate>
    
	<atom:link href="https://fuweid.com/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>eBPF 动态观测之指令跳板</title>
      <link>https://fuweid.com/post/2022-bpf-kprobe-fentry-poke/</link>
      <pubDate>Sun, 12 Jun 2022 12:00:53 +0800</pubDate>
      
      <guid>https://fuweid.com/post/2022-bpf-kprobe-fentry-poke/</guid>
      <description>在 containerd 自定义插件 embedshim 项目里，我借助了 Linux 内核里的 trace_sched_process_exit 观测能力，并利用 eBPF Map 记录和持久化容器进程退出事件。 这类观测能力依赖内核在关键代码路径上提前定义好钩子，它属于静态观测技术，任何变化都需要重新编译 Linux 内核。 如果我们想观测内核中的某一个关键函数或者某一行关键代码时，我们可以选择 kprobe 或者 ftrace 这类动态观测技术。
kprobe - single-step Kernel Probe(kprobe) 是一个轻量级内核指令观测的技术，用户可以指定观测内核的某一个函数，甚至可以观测函数内的某一条指令，除了 kprobe 框架自身的代码以及异常处理函数外，用户几乎可以观测内核运行的每一条指令。
当 CPU 执行到被观测指令时，也就是产生了一次 观测事件，那么 kprobe 会把当前 CPU 的寄存器信息作为输入去执行用户注册的观测程序。 然而被观测的指令由用户随机指定，考虑到性能问题，kprobe 无法在编译内核时为每一条指令预留埋点，同时我们很难在编译好的程序里动态插入指令。 基于性能和稳定性考虑，kprobe 选择了 单步调试 的通用方案。
在介绍 kprobe 方案之前，我们先简单回顾下 gdb 调试过程。为了调试某一行代码，我们先通过 breakpoint 给该行打上断点，当程序运行到该行代码时就会停下来，等待我们的下一步交互。 这个时候我们就可以通过 p 或者 info 等命令来查看当前程序的状态，甚至我们还可以通过 单步调试 来观察程序每条指令带来的变化。 我们利用断点和单步调试产生的 停顿 来观测程序，这本质上也是一种埋点，内核也正是通过这种方式来实现 kprobe，如下图所示。
x86_64 CPU 架构下的断点指令为 INT3，它是一个单字节指令 0xcc 。我们可以用 INT3 来替换任何指令的 opcode，被替换的指令（以及后续指令）都将被中断所短路掉，而 CPU 将进入 do_int3 [1] 中断处理逻辑。</description>
    </item>
    
    <item>
      <title>embedshim: 内核是我的边车</title>
      <link>https://fuweid.com/post/2022-embedshim-kernel-is-my-sidecar/</link>
      <pubDate>Mon, 02 May 2022 18:20:45 +0800</pubDate>
      
      <guid>https://fuweid.com/post/2022-embedshim-kernel-is-my-sidecar/</guid>
      <description>在 2019 年的时候，当时所在的团队正在开始大规模使用 containerD，我们初期遇到较多 containerd-shim 的死锁等稳定性问题，我们不得不去思考去除 containerd-shim 进程的可能性。由于当时技术选型上的限制，containerd-shim 必须作为容器 subreaper 而存在。直到去年才留意到 pidfd pollable，我才发现 containerd-shim 管控面其实是可以被移除。我顺着这个思路作出了 embedshim 这个 containerD 第三方插件。在介绍这个插件之前，我们先简单回顾下 containerd-shim 的发展历程。
1. 从 docker 的原地升级到 containerd-shim 1.1 原地升级的需求 最初 dockerd 的容器进程管理是非常简单粗暴的，它采用了 Fork-and-Wait 模式来监控容器状态，并通过无名管道接管容器的标准输入输出。如果 dockerd 进程重启，那么它将无法重新监控容器的状态变化，而这些已运行的容器都将变成 孤儿。为了防止资源残留，dockerd 重启后的第一件事就是停掉正在运行的容器。然而节点组件的重启和周期性升级都属于正常操作，dockerd 停服重启应保证正在运行的容器不受影响。
这 docker#2658 帖子记录了当时 dockerd 原地升级的细节讨论；当然除了方案讨论外，用户对该需求落地呼声评论是更强烈些的。组件进程重启涉及到的细节比较多，但可以归类为状态恢复以及临时（残留）数据的清理，比如有讨论清理未完成的网络初始化资源，有讨论如何恢复接管容器的标准输出，还有讨论如何做镜像下载的断点续下等等。而对于本文的主题 - 如何重新接管存量容器进程的场景而言，个人认为仅需要考虑下面两个问题即可：
 如何保证容器退出事件不丢失？ 如何重新接管容器的标准输入输出？  首先，我们来看第一个问题。进程退出码能正确反映一个进程是以什么状态结束的，有正常退出的，有收到 SIGTERM 信号优雅停服的，还有因无法分配新的内存而被内核 SIGKILL 的。开发者和运维人员可以根据进程退出码以及关键日志信息来做 非预期退出事件 的诊断，所以对于进程管理方案而言，进程退出码必须要能被正确捕获，而当时最稳妥的方式是有一个常驻进程来做容器进程的 subreaper。
相比于第一个问题，第二个问题处理起来要简单些。经历过早期节点运维的朋友都知道，在容器化之前呢，大部分业务进程的管理是通过 systemd-service 来实现。业务进程直接被一号进程所监管，同时它们采用了 Headless 无界面无交互的方式运行。它们的标准输出通常以 UDS 流的形式传递给 systemd-journald 服务，由 systemd-journald 来做日志持久化和轮动存储。
容器化后的节点运维比 systemd 模式要稍微复杂些。容器化产生了根路经和资源视图隔离，容器管理面需要封装 nsenter 和 chroot/pivot 等系统调用来提供便捷的运维通道。dockerd 进程提供了 execCreate/execStart/execAttach HTTP 接口来进入到容器隔离视图，这种具有交互能力的运维通道必定会感知 dockerd 停服。但个人认为这种感知是可接受的，只要能保证容器标准输出不因 dockerd 停服而丢失即可。在标准输入输出的接管上，dockerd 并没有采用 UDS 流模式，而是采用有名管道的方式。</description>
    </item>
    
    <item>
      <title>Towards truly portable eBPF</title>
      <link>https://fuweid.com/post/2022-ebpf-portable-with-btfhub/</link>
      <pubDate>Thu, 10 Mar 2022 00:00:45 +0800</pubDate>
      
      <guid>https://fuweid.com/post/2022-ebpf-portable-with-btfhub/</guid>
      <description>在上一篇 eBPF Loader 中介绍了 eBPF 加载器的工作原理。Compile-Once Run-Everywhere (CO-RE) 是目前社区的发力方向，但它要求内核版本支持 CONFIG_DEBUG_INFO_BTF=y 特性。除了 REHL 等商业公司会回合高版本特性到当前支持的商业版本之外，大部分社区免费版本都要求 &amp;gt;= 5.5 版本的内核。为了能在当前主流的 4.14, 4.15, 4.18, 4.19 内核版本上支持 eBPF CO-RE 特性， Aqua Security 的工程师在 2021 Linux Plumbers Conference - Towards truly portable eBPF 议题上展示了它们的想法: BTF-Hub + Embedded BTF。
1. BPF Portable 作为用户提供的程序片段，eBPF bytecode 可直接注入到 linux 内核里直接读取和操作内核运行态的内存数据，它的可观测性和对内核模块的可拓展性受到系统开发者的青睐。这是它强大的优势，但同时也是一大痛点：只有获得了目标内核版本的头文件才能保证 eBPF 程序能正确地访问内存数据。
早期在使用 bcc 诊断工具时，我们需要 llvm/clang 做 eBPF 实时编译；如果开发 - 测试 - 线上环境没有做到版本的强一致，那么即使逃过了 BPF Verifier 的审判，程序也会因为没有正确地读取内存 (偏移地址不正确) 而出现非预期的行为。
虽然 eBPF 程序的非预期行为不会导致内核崩溃，但研发体验和内核模块开发差别不大：eBPF 开发者还是需要针对不同的内核版本编译出不同的版本，线上内核版本越多，测试上线的成本就越高。下图为 Falco 为不同版本提供的内核模块；如果 eBPF 没有移植能力的话，它的发布模式其实和普通的内核模块差别不大。一次构建，到处运行 的能力直到 BPF Type Format (BTF) 的出现才有了质的飞跃。</description>
    </item>
    
    <item>
      <title>eBPF Loader</title>
      <link>https://fuweid.com/post/2022-ebpf-loader/</link>
      <pubDate>Sun, 27 Feb 2022 23:00:53 +0800</pubDate>
      
      <guid>https://fuweid.com/post/2022-ebpf-loader/</guid>
      <description>0. What is eBPF? Extended Berkeley Packet Filter (eBPF) 是由 Linux 提供的内核技术，它是以安全沙盒 (Virtual Machine) 的形式运行用户定义的 ByteCode 来观测内核运行状态以及拓展内核的能力，开发者无需定制内核模块就可以高效地完成对现有模块的拓展。eBPF 安全沙盒是嵌入到 Linux 内核运行态的关键路径上，通过事件订阅的形式来触发 eBPF 程序，其运用场景有：
 cilium 在 L3/L4 提供高效的网络转发能力 bcc 提供常用的观测组件来定位业务遇到的性能问题 Google 内核调度拓展 ghOSt  我过去主要使用 eBPF 在观测和排查一些节点的性能问题。由于底层基础设施能力以及业务运行模型存在差异，这将导致节点组件出现不在预期内的行为，而在本地又难以复现，大大增加了沟通和排查成本。而 eBPF 可以捕捉到程序在内核里的状态，甚至是短命的程序调用 (比如容器领域的 runC 命令) 都可以捕捉, 它可以最大程度地呈现程序的运行状态来提升问题的排查效率。
比如前段时间遇到的 containerD CRI 组件创建容器超时的问题，我通过 bcc stackcount 捕抓到 根因: umount 可写的文件系统时会调用底层文件系统的刷盘动作，它用来保证数据能及时落盘；但这同时也给磁盘带来压力，IOPS 弱的数据盘将会拖慢 umount 调用。对于一个不熟悉内核代码的开发者来说，eBPF 观测类工具暴露出的关键函数路径就和日志的错误信息一样，全局搜索相应的内核代码段，然后顺藤摸瓜，总会找到些蛛丝马迹。
eBPF 目前发展的比较快，其中一个重要的支线是 Compile-Once Run-Everwhere (CO-RE) ，这有点像 docker 镜像分发的 Build-Once Run-Anywhere, 下面将主要围绕兼容性去介绍如何加载 eBPF 程序。</description>
    </item>
    
    <item>
      <title>go sync.Mutex 源码阅读</title>
      <link>https://fuweid.com/post/2020-go-sync-mutex-insight/</link>
      <pubDate>Sun, 21 Jun 2020 18:00:53 +0800</pubDate>
      
      <guid>https://fuweid.com/post/2020-go-sync-mutex-insight/</guid>
      <description>Linux Kernel 提供 Semaphore/Mutex 来实现线程间的同步机制，可保证在同一个时间段 只有少量的线程可以访问同一块资源（也称为进入临界区域）。 线程之间要通过竞争来获得访问权限，一旦竞争失败，线程会进入到阻塞状态； 而阻塞的线程只能等待离开临界区域被内核唤醒。
go runtime 提供的 sync.Mutex 并不是采用内核级别的同步机制。 作为执行单元的线程一旦阻塞，意味该线程将不再受到 go runtime 控制， go runtime 需要创建新的线程来执行其他 runnable goroutine ， 线程的数目会和竞争资源的请求成正比，容易造成资源浪费。 而 go 优势是 goroutine 轻量级调度，因此 sync.Mutex 选择在用户态来实现同步机制。
和线程阻塞类似，在无法进入临界区的情况下，goroutine 会主动释放当前的 执行单元 - 线程，进入到阻塞状态；在 sync.Mutex 持有者离开临界区之前， 阻塞状态的 goroutine 将不会出现在调度队列里。 这样被释放的线程会去执行其他 runnable goroutine，提升线程的利用率。
sync.Mutex 结构设计分析 Mutex 也被称之为锁。
// sync/mutex.go  // A Mutex is a mutual exclusion lock. // The zero value for a Mutex is an unlocked mutex. // // A Mutex must not be copied after first use.</description>
    </item>
    
    <item>
      <title>可以同时对一个 go string 进行读写操作吗？</title>
      <link>https://fuweid.com/post/2020-go-string-data-race/</link>
      <pubDate>Sat, 30 May 2020 00:00:00 +0800</pubDate>
      
      <guid>https://fuweid.com/post/2020-go-string-data-race/</guid>
      <description>写过 Go 代码的同学都知道，在程序内启动多个 goroutine 处理任务是很常见的事情， 启动一个 goroutine 要比启动一个线程简单的多。当多个 goroutine 同时处理同一份数据时， 我们应该在代码中加入同步机制，保证多个 goroutine 按照一定顺序来访问数据， 不然就会出现 data race。 最常见的例子如下，同时写操作 map 数据会导致程序 panic，即使操作的是不同 key：
// example 1  package main func main() { for { c := make(chan bool) m := make(map[string]string) go func() { m[&amp;#34;1&amp;#34;] = &amp;#34;a&amp;#34; // First conflicting access.  c &amp;lt;- true }() m[&amp;#34;2&amp;#34;] = &amp;#34;b&amp;#34; // Second conflicting access.  &amp;lt;-c } } 那么下面的代码也会 panic 吗？
// example 2 // 1 package main 2 3 import &amp;#34;sync&amp;#34; 4 5 func main() { 6 var wg sync.</description>
    </item>
    
    <item>
      <title>在线看 O&#39;Reilly 动物新书指南</title>
      <link>https://fuweid.com/post/2020-digital-book-from-safari/</link>
      <pubDate>Sat, 21 Mar 2020 00:00:00 +0800</pubDate>
      
      <guid>https://fuweid.com/post/2020-digital-book-from-safari/</guid>
      <description>想当初，为了看 Operating Systems: Three Easy Pieces 和 A Philosophy of Software Design 原版技术书，还特别麻烦了朋友从国外人肉带回来，成本极高。 但如果等国内出版社引进，就会出现时间跨度太大没法尝鲜；加上翻译水平参差不齐，等待中文版的路子基本上行不通。 为了解决这个尴尬问题，最近找到了一个比较实惠看国外原版书籍的方式：ACM Professional Membership。
ACM Professional Membership 会员权益 有很多，其中有一项是：
 Learning Center with resources for lifelong learning, including online courses targeted toward essential IT skills and popular certifications; online books &amp;amp; videos from Skillsoft®, online books from O&amp;rsquo;Reilly®, Morgan Kaufmann and Syngress; videos and webinars on hot topics, presented by today&amp;rsquo;s innovators
 会员可以享受学习平台，其中包含了 O&amp;rsquo;Reilly online books。 平时在网上买技术书籍，基本上都能看到 O&amp;rsquo;Reilly 动物封面书籍，比如 Site Reliability Engineering。 这个出版社覆盖的书籍比较多，基本上能满足我大部分阅读需求。 本着怀疑的态度看这个权益，没想到尝试之后，真香。</description>
    </item>
    
    <item>
      <title>Hola Barcelona</title>
      <link>https://fuweid.com/post/2019-hola-barcelona/</link>
      <pubDate>Sun, 02 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://fuweid.com/post/2019-hola-barcelona/</guid>
      <description>前段时间因为 KubeCon 演讲去了趟西班牙-巴塞罗那，忙里偷闲，感受了下西方文化。
不再是「白本」 5.18 号从杭州出发，途径香港转机到巴塞罗那。飞机上的娱乐设施还算丰富，「海王」、「绿皮书」等新片都可以观看到。十几个小时的飞机总不能一直看电影，还得兼顾倒时差的任务。
之前没有调整时差的经验，加上平时作息比较规律，十三个小时的飞行过程里相对属于清醒状态。网络要收费，印象中比较贵，基本上干不了别的事情，除了看电影就是睡觉。如果经济允许，可以考虑升舱，坐经济舱飞十几小时简直了。到达 巴塞罗那 是当地时间早上8点，天气还算不错，就是有点过于「凉快」，完全没有夏天的感觉。上了摆渡车，直奔海关。
当地的海关工作人员整体都不严肃，有些还带着耳机工作，有点不可思议。轮到我的时候，那位海关小哥看了我半天，感觉不像，盖章的时候特别犹豫，而且盖完章之后他应该是后悔了，还用类似验钞机的东西反复扫描我的签注，最后才说「Wei Fu, Welcome」。
说句实在话，我当时的反应是这签证不会特么是假的吧，因为从广州签证处提交申请到拿到签证只花了「三天」，申请港澳通行证都没有那么快。还好，有惊无险。
骑行友好的街道 虽然没有游玩整个 巴塞罗那 ，但是可以感觉到城市的大部分街道都是单行道。我在早高峰的时候打过车，车多但不算堵。
说到打车，这里的打车算是一件高消费的服务了。我没有用 Uber/MyTaxi 软件打车，大部分都是通过酒店来约车，而这种约车是需要收调度费，大概2-3 欧左右吧。接近4公里左右的路程要 15 欧，贵！
可能是养一辆车的费用比较高吧，这座城市的摩托车特别多，几乎随处可见。比较有意思的是摩托车车锁，他们的车锁是锁车把和车身，基本上不需要下蹲去锁车。
虽然北京也有自行车道，但是大部分都被私家车占用了，对骑行的人来说极度不友好。这边的街道基本是两车道配一个自行车道，而汽车道和自行车道基本上严格分开，有些地方还有隔离带，对爱骑车的人来说真是太幸福了。
如果你打开 Mobike，估计还会有惊喜哦。
地铁，还不算太破 我住的酒店离地铁站不远，走几个街头就可以到达地铁站。在长达 15 个小时日照时间里，在拓展区里步行还算安全，也比较舒服。
随处可见的遛狗人士，转角处的饮酒闲谈，还有无法欣赏的涂鸦。建筑都相对破旧，估计这十几年的变化也就是街上跑的私家车了。
不管是去日本，还是来到 巴塞罗那，这边的地铁和火车一样，发车和到达时间点都是严格规定好的。这有个好处就是，每天都可以踩点出发。
整个城市的地铁覆盖范围还是比较大，就是不同的区域由不同的公司运营，换乘基本上要出站重新购票了。如果不买套票，单程票就要 2.2 欧，贵的一匹。刷票进站后，给人感觉就是简陋，但不算太破。
语言？No English 巴塞罗那 选择的时区和德国好像是一样的，都是东一区。在夏天，他们日照时间有 15 小时，到晚上 9 点天还是亮的。
因为长时间日照的原因，他们物产是比较丰富的。但是想不明白的是，他们这边的特产是「西班牙火腿」。这火腿是腌制好几年而成，吃的时候切的越薄口感越好。主要这是生肉。。。
和当地的「潮州佬」店主聊，他们当地喜欢吃「生」，日料店相对中餐而言要受欢迎些，估计是好吃「生」的食材吧。尝过 Tapa，也看过所谓的海鲜饭，还是觉得国内的菜还吃。
出去吃饭更要命的是，点菜的时候没有图片，加上有些还没有英文注释，基本就瞎了。看不懂可以问吧，但是这边的人不太会说英语，也不愿意说。你可以想象下，机场里的工作人员会直接对你「No English」。这体验真的比去日本还糟糕。
一直在「修」 城市比较小，到达的第一天就小转了一圈。
因为加泰罗尼亚要闹独立，涂鸦就是这边的独特的风景线。从酒店走到港口，街道上的店铺都没开门。问了下当地国人，说这边的人比较懒，周末基本都享受去了，开便利店的基本都是非本地人。
一路上都有海鸥到处飞，海鸥也不怕人，基本给啥吃啥，爆米花都吃！
在港口溜达一会，就去看世界上最著名的「烂尾楼」 - 「圣家族大教堂」。这座大教堂修了 100 年，因为修的时间是在太长了，不知道是不是中间换了几个设计师，教堂每个角度的风格都不太一样。不过这也算是巴塞罗那著名景点了，只可惜当天去的时候没有门票了，没能进去。
最后 这次出国没准备攻略，基本上是很佛系地逛了下，剩下大部分时间都在准备演讲内容。不过怎样，出远门才觉得国内是真TM方便。</description>
    </item>
    
    <item>
      <title>工作三年</title>
      <link>https://fuweid.com/post/2018-3years-career/</link>
      <pubDate>Fri, 13 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://fuweid.com/post/2018-3years-career/</guid>
      <description>不知不觉就过了三年，但是我还能很清楚地记得当时签卖身契的场景，只能说毕业之后时间过的飞起。这三年没写过什么年度总结，今天打算矫情一把，记下流水账。
Vimer 有一次参加罗老师开发环境的分享会后，我就开始迷上 vim，并结束了 IDE/Sublime 之间的摇摆。从实用角度看，IDE 有着开箱即用的特点，这的确让人无法抗拒。但在平时的工作里，不同语言之间切换是常有的事，而且经常远程调试、常年沉浸在 Terminal 的我，vim 作为编辑器是一个不错的选择。加上韩国小哥 junegunn 开源神器 fzf ，解决了 vim 全文检索巨卡的痛点，这让我毫不犹豫地坚持使用 vim。没试过 fzf 的朋友不妨试试！
我在习惯 HJKL 的同时，也在尝试回馈社区。还记得刚用 fzf.vim 的时候，当时的全文检索没有预览功能，相比于 Sublime，几乎没法用。所以在参加完公司第二个 Hackathon 之后的那个周末提了人生的第一个 PR。在这期间和韩国小哥 junegunn 来来回回讨论了快一个月，虽然最后失败了，但是我很享受这期间的沟通过程，毕竟能把自己的想法表达清楚是一件难得的事，因为非实时的沟通一旦出现理解偏差，时间成本将会急速上升。
在后来使用了 vim-delve 插件，并帮助作者修复了几个 bug，也算是回馈社区了~
MIT 6.828 在 16 年年初，非计算机专业的我选择了恶补操作系统：MIT 6.828。
前前后后花了三个周末完成所有基本要求。课程设计者虽然尽可能地避免了琐碎的硬件操作，但是这三个周末还是非常的虐，毕竟 x86 架构有很多历史包袱，需要阅读 Intel x86 的开发文档。。。这三个周末完成的玩具内核让我重新认识了操作系统， 对我后续的工作帮助极大。
不过你们会相信恶补的原因只是想知道 fork 怎么做到两个返回值 吗？
Gopher 语言切换算是这三年里最大的变化吧。为了看 Docker 的代码而接触 Golang，但是在16年年底的时候公司并没有项目让我去实践，当时的我只能自己啃代码，等到真正实践的时候也差不多到17年年中了。
去年七八月我偶然发现 PingCAP 有赠马克杯的 TiDB 重构活动，很幸运的是提的三个 PR 都被接受了，这也是我第一次在 Github 上贡献代码。再后来就是 Pouch，因为对容器的喜爱吧，几乎大部分的空闲时间都参与到 Pouch 上来了。
除了代码以外，还因为 Golang 开源项目结识了一些朋友，不得不说真是名副其实的 G**hub。</description>
    </item>
    
    <item>
      <title>Goroutine Scheduler Overview</title>
      <link>https://fuweid.com/post/2018-goroutine-scheduler-overview/</link>
      <pubDate>Tue, 06 Feb 2018 00:00:00 +0800</pubDate>
      
      <guid>https://fuweid.com/post/2018-goroutine-scheduler-overview/</guid>
      <description>Goroutine 是 Golang 世界里的 Lightweight Thread 。
Golang 在语言层面支持多线程，代码可以通过 go 关键字来启动 Goroutine ，调用者不需要关心调用栈的大小，函数上下文等等信息就可以完成并发或者并行操作，加快了我们的开发速度。 分析 Goroutine 调度有利于了解和分析 go binary 的工作状况，所以接下来的内容将分析 runtime 中关于 Goroutine 调度的逻辑。
 以下内容涉及到的代码是基于 go1.9rc2 版本。
 1. Scheduler Structure 整个调度模型由 Goroutine/Processor/Machine 以及全局调度信息 sched 组成。
 Global Runnable Queue runqueue ---------------------------- | G_10 | G_11 | G_12 | ... ---------------------------- P_0 Local Runnable Queue +-----+ +-----+ --------------- | M_3 | ---- | P_0 | &amp;lt;=== | G_8 | G_9 | +-----+ +-----+ --------------- | +-----+ | G_3 | Running +-----+ P_1 Local Runnable Queue +-----+ +-----+ --------------- | M_4 | ---- | P_1 | &amp;lt;=== | G_6 | G_7 | +-----+ +-----+ --------------- | +-----+ | G_5 | Running +-----+ 1.</description>
    </item>
    
    <item>
      <title>Protobuf 3.0 编码</title>
      <link>https://fuweid.com/post/2017-protobuf-3-encoding/</link>
      <pubDate>Wed, 15 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://fuweid.com/post/2017-protobuf-3-encoding/</guid>
      <description>Protobuf 是 G 厂开源的序列化数据的方法，可用来通信或者存储数据。它采用 IDL 描述数据接口，使得不同语言编写的程序可以根据同一接口通信。不同编程语言也可以根据 IDL 的描述来生成对应数据结构，该数据结构用来编解码。为此，G 厂为主流开发语言都提供代码生成器（即 protoc ）。
为了更好地了解一些细节，本文将主要描述 Protobuf 3.0 的编码规则。 Protobuf 里面主要采用 Varint 和 Zig-Zag 的方式来对整型数字进行编码。在理解 Protobuf 之前，需要先了解这两种编码方式。
 Protobuf 采用是 Little Endian 的方式编码。
 1. Varints int64, int32, uint64, uint32 都有固定的二进制位数。
如果将这些数字序列化成二进制流的时候，需要额外空间告知接收方数据的长度。对于采用 int64, uint64 这两种类型的数据而言，如果大部分时间都只是使用较小的数值，那么会极大地浪费传输带宽和存储空间。针对这两个问题，Protobuf 采用 Varints 的编码方式。
Varints 将源数据按照 7 bit 分组，每 7 bit 加 MSB (Most Significant Bit) 标识位来组成一个字节，其中 MSB 标识位用来判断是否存在后序分组。如果出现多组的情况，那么低有效位比特组优先。
64 有效位为 7 bit，不需要额外的字节，所以 MSB 比特位为 0。
64 = 0100 0000 =&amp;gt; 0100 0000 16657 有效位为 15 bit，需要分成三组字节，前两组字节为了提示还存在后续字节，所以前两组字节的 MSB 比特位为 1。</description>
    </item>
    
    <item>
      <title>Go Interface &amp; Duck Typing</title>
      <link>https://fuweid.com/post/2017-go-interface-duck-typing/</link>
      <pubDate>Mon, 05 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://fuweid.com/post/2017-go-interface-duck-typing/</guid>
      <description>Go 不需要像 Java 那样显式地使用 implement 说明某一数据类型实现了 interface，只要某一数据类型实现了 interface 所定义的方法名签，那么就称该数据类型实现了 interface。interface 的语言特性可以容易地做到接口定义和具体实现解耦分离，并将注意力转移到如何使用 interface ，而不是方法的具体实现，我们也称这种程序设计为 Duck Typing。文本将描述 Go 是如何通过 interface 来实现 Duck Typing。
 本文提供的源代码都是基于 go1.7rc6 版本。
 1. Duck Typing 了解实现原理之前，我们可以简单过一下 Go 的 Duck Typing 示例。
package main type Ducker interface { Quack() } type Duck struct {} func (_ Duck) Quack() { println(&amp;quot;Quaaaaaack!&amp;quot;) } type Person struct {} func (_ Person) Quack() { println(&amp;quot;Aha?!&amp;quot;) } func inTheForest(d Ducker) { d.Quack() } func main() { inTheForest(Duck{}) inTheForest(Person{}) } // result: // Quaaaaaack!</description>
    </item>
    
    <item>
      <title>让你的 shell 脚本变得可控</title>
      <link>https://fuweid.com/post/2017-control-your-shell-script/</link>
      <pubDate>Mon, 20 Mar 2017 00:00:00 +0800</pubDate>
      
      <guid>https://fuweid.com/post/2017-control-your-shell-script/</guid>
      <description>刚开始接触 shell 脚本的时候，最痛苦的地方在于出了问题，却不容易定位问题。
shell 脚本遇到错误，“大部分” 情况下都会继续执行剩下的命令，最后返回 Zero Exit Code 并不代表着结果正确。
这让人很难发现问题，它不像其他脚本语言，遇到 语法错误 和 typo 等错误时便会立即退出。
如果想要写出容易维护、容易 debug 的 shell 脚本，我们就需要让 shell 脚本变得可控。
set -e 默认情况下，shell 脚本遇到错误并不会立即退出，它还是会继续执行剩下的命令。
[root@localhost ~]# cat example #!/usr/bin/env bash # set -e sayhi # this command is not available. echo &amp;quot;sayhi&amp;quot; [root@localhost ~]# ./example ./example: line 4: sayhi: command not found sayhi 我们知道 Linux/Unix 用户等于系统的时候，内核会加载 .bashrc 或者 .bash_profile 里的配置。
 不同 shell 版本会使用不同的 rc/profile 文件，比如 zsh 版本的 rc 文件名是 .</description>
    </item>
    
    <item>
      <title>shebang - #!</title>
      <link>https://fuweid.com/post/2017-shebang-compatibility-version/</link>
      <pubDate>Sun, 19 Mar 2017 00:00:00 +0800</pubDate>
      
      <guid>https://fuweid.com/post/2017-shebang-compatibility-version/</guid>
      <description>写脚本的时候通常会在脚本的开头加上 shebang, 系统会将这段内容作为解释器指令，比如 bash shell 脚本。
$&amp;gt; cat example #!/usr/bin/bash echo &amp;quot;HaHa&amp;quot; $&amp;gt; chmod +x ./example $&amp;gt; ./example HaHa 只要为脚本添加了可执行的属性，那么内核在执行脚本的时候，会调用 shebang 描述的解释器来执行脚本。 ./exmaple 其实等价于 /usr/bin/bash ./example。shebang 描述的解释器需要写其绝对路径或者相对路径，因为内核并不会在用户设置的 PATH 里找解释器。关于 shebang，讨论最多的应该是 兼容性 和 版本控制 问题。
兼容性 Linux 和 Unix 在存放解释器的具体路径不太一致，比如 Linux 会放到 /usr/bin/ 中，而 openBSD 会放到 /usr/local/bin/ 中。不同包管理器在安装解释器的时候，存放的位置也不尽相同。 当你在 Mac 上写了 shell 脚本，测试并提交到代码库。 结果等到部署的那一天，执行脚本的时候发现找不到解释器了。 为了解决这个问题，可以通过 env 来解决，因为它在 Linux 和 Unix 存放的位置相同。
$&amp;gt; cat exmaple #!/usr/bin/env bash echo &amp;#34;HaHa&amp;#34; env 会在用户设置的 PATH 中查找解释器第一次出现的具体路径。 虽然办法比较 tricky，但是这种方式能解决脚本解释器的兼容性问题。</description>
    </item>
    
    <item>
      <title>Netfilter 初探</title>
      <link>https://fuweid.com/post/2017-netfilter-beginning/</link>
      <pubDate>Fri, 17 Mar 2017 00:00:00 +0800</pubDate>
      
      <guid>https://fuweid.com/post/2017-netfilter-beginning/</guid>
      <description>Linux 内核在 2.4.x 版本中正式引入 Netfilter 模块，该模块负责网络数据包过滤和 Network Address Translation。 Netfilter 代表着一系列的 Hook ，被内核嵌入到 TCP/IP 协议栈中，数据包在穿梭协议栈时，Hook 会检查数据包，从而达到访问控制的作用。
规则链 Netfilter 模块默认定义了五种类型的 Hook：
 PREROUTING INPUT FORWARD OUTPUT POSTROUTING   在 Netfilter 里，Hook 也称为 Chain，规则链
 我们可以从数据包的来源和走向入手来进行分析这条五条规则链的设计。 首先，数据包按照来源可以分成 Incoming 和 Outgoing 这两种类型。 Incoming 数据包是指其他网卡发来的数据包。这类数据包可能直接奔向用户态的程序， 也有可能被内核转发到其他机器或者其他网卡上，这需要内核做路由判定。
而 Outgoing 数据包是用户态程序准备要发送的数据包。 数据包到达内核之后，内核会为它选择合适的网卡和端口，在此之后便会一层层地穿过协议栈，内核在此过程之中会做出路由判定。
 一般情况下，客户端所使用的高端口号。在 Linux 下，我们可以通过 cat /proc/sys/net/ipv4/ip_local_port_range 查看系统会随机使用的端口号范围。
 需要注意的是，如果这是内网和外网之间的通信，内核会使用到 NAT 技术来对地址进行转化。 对于 Incoming 数据包而言，内核路由前需要对数据包进行 Destination NAT 转化。 同理，数据包在路由之后也需要做 Source NAT 转化。
根据上面的分析，可以得到以下结论：
 Incoming 数据包的目的地就在本地：PREROUTING -&amp;gt; INPUT Incoming 数据包需要转发：PREROUTING -&amp;gt; FORWARD -&amp;gt; POSTROUTING Outgoing 数据包：OUTPUT -&amp;gt; POSTROUTING  不同走向的数据包都必定会通过以上五个环节中的部分环节，只要系统管理员在五个环节中设置关卡，就可以做到系统的访问控制。</description>
    </item>
    
  </channel>
</rss>