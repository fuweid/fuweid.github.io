<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>脏页大小 - 18446744073709551614 ?! | fuweid</title>
<meta name=keywords content><meta name=description content="etcd-io/etcd#17615"><meta name=author content><link rel=canonical href=https://fuweid.com/post/2024-dirtypage--2/><link crossorigin=anonymous href=/assets/css/stylesheet.bc1149f4a72aa4858d3a9f71462f75e5884ffe8073ea9d6d5761d5663d651e20.css integrity="sha256-vBFJ9KcqpIWNOp9xRi915YhP/oBz6p1tV2HVZj1lHiA=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://fuweid.com/favicon.jpg><link rel=icon type=image/png sizes=16x16 href=https://fuweid.com/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://fuweid.com/favicon-32x32.png><link rel=apple-touch-icon href=https://fuweid.com/apple-touch-icon.png><link rel=mask-icon href=https://fuweid.com/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://fuweid.com/post/2024-dirtypage--2/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-1C7VLVHN52"></script><script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-1C7VLVHN52",{anonymize_ip:!1})}</script><meta property="og:title" content="脏页大小 - 18446744073709551614 ?!"><meta property="og:description" content="etcd-io/etcd#17615"><meta property="og:type" content="article"><meta property="og:url" content="https://fuweid.com/post/2024-dirtypage--2/"><meta property="article:section" content="post"><meta property="article:published_time" content="2024-04-11T20:48:45+08:00"><meta property="article:modified_time" content="2024-04-11T20:48:45+08:00"><meta property="og:site_name" content="fuweid"><meta name=twitter:card content="summary"><meta name=twitter:title content="脏页大小 - 18446744073709551614 ?!"><meta name=twitter:description content="etcd-io/etcd#17615"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://fuweid.com/post/"},{"@type":"ListItem","position":2,"name":"脏页大小 - 18446744073709551614 ?!","item":"https://fuweid.com/post/2024-dirtypage--2/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"脏页大小 - 18446744073709551614 ?!","name":"脏页大小 - 18446744073709551614 ?!","description":"etcd-io/etcd#17615","keywords":[],"articleBody":"分享一个 etcd-io/etcd@17615 问题：用户发现 etcd 进程写入 WAL 日志有抖动，但是磁盘压力并不大，而且 fsync 系统调用都很正常； 后来通过 Tracing 工具定位到了内核 memory-cgroup 脏页数据统计有问题，不过该问题仅会出现在 v5.15.0-63 小版本。 17615 问题单里有详尽的定位过程，推荐看看。 因为这个问题，我翻阅了相关的内核 PATCH 邮件，做了以下的脏页分配限流 (简单) 总结。\n脏页分配限流 - balance_dirty_pages 回写 (Writeback) 是指内核负责将脏页 (DirtyPage) 刷入存储设备上，它涉及到脏页分配控制。\n在 v4.2 版本之前，脏页分配更多是由 memory-cgroup 来控制；而脏页流控核心 - balance_dirty_pages - 根据全局的脏页水位情况来决定是否需要控速。 在 LinuxCon Japan 2015 会议上，内核开发者 Tejun Heo 认为，在没有感知到全局脏页水位的情况，memory-cgroup 无法对脏页进行有效的控制。 核心 balance_dirty_pages 函数通过 vm.dirty[_background]_{ratio, bytes} 参数来计算全局脏页的水位上限。 Tejun Heo 认为普通的 memory-cgroup 也应采用同样的方式来计算组内的脏页水位上限，而根组 memory-cgroup 只不过是退化到全局模式，当然全局脏页的水位优先级更高。\nNOTE: balance_dirty_pages_ratelimited 会调用 balance_dirty_pages。\n在 writeback: cgroup writeback support PATCH 合并到 v4.2 之后，每个 memory-cgroup 都有独立的设备回写控制器 (bdi_writeback)，它用于执行回写操作。 回写控制器维护写入带宽 - dirty_ratelimit - ，初始状态下为 100 MiB/s。假设当前脏页大小为 dirty 和同时有 N 个线程在写入，该线程需要等待的时长大约为\npause = dirty / (dirty_ratelimit / N) 在 writeback: dirty rate control PATCH 里，内核开发者 Wu Fengguang 给出了 N = roundup_pow_of_two(1 + HZ / 8) 的计算方法； 自 2011 年以来，内核一直在使用该方法计算 N。 让线程停顿是为了防止脏页增长过快。但如果整体可用内存水位状态良好，内核应该尽量避免不必要的停顿，因此脏页水位有三个状态 freerun, setpoint 和 limit。\nthreshold = vm.dirty_ratio * total_available_memory background_threshold = vm.dirty_background_ratio * total_available_memory * freerun = (threshold + background_threshold) / 2 * limit = threshold * setpoint = (freerun + limit) / 2 当脏页水位线低于 freerun 时，那么线程并不需要停顿，内存允许脏页快速增长；当脏页水位高于 limit 时，内核将通过 sleep(pause) 来禁止线程写入新的脏页，内核需要通过回写来降低水位线到安全的位置。 为了更好地计算停顿时长，内核引入了线程级别的带宽概念 task_ratelimit: 利用水位状态 pos_ratio 来调节写入带宽。\n* pos_ratio(dirty) = 1.0 + ((setpoint - dirty) / (limit - setpoint) ) ^3 * task_ratelimit(dirty) = dirty_ratelimit * pos_ratio(dirty) * pause = dirty / (task_ratelimit / N) 内核还会根据 IO 回写控制器的情况来微调 pos_ratio，尤其是在内存较大的机器上能充分利用内存优势， 通过维持较高的写入带宽来迅速降低脏页水位线，细节可以查询 writeback: dirty position control PATCH。\nmemory-cgroup 脏页状态更新 - rstat 当进程跑在非根组的 memory-cgroup 时，balance_dirty_pages 需要从对应 memory-cgroup 获取当前的脏页大小。\n2019 年 mm: memcontrol: make cgroup stats and events query API explicitly local PATCH 让内核在更新侧 (内存的分配和释放) 做 per-cpu 的批量数据聚合，减少读取侧因遍历 memory-cgroup 树形结构测带来的 CPU 消耗。 假设每次更新 32 个页的数据，在 32 CPU 下运行着 32 个 memory-cgroup，那么最大误差会在 128 MiB 左右。 为了解决误差和读取效率问题，内核开发者 Johannes Weiner 在 mm: memcontrol: switch to rstat PATCH 里引入了 rstat 框架: 更新侧仅需为祖辈们维护 pending-update cgroup 队列，而读取侧仅选择性地做数据聚合，减少了不必要的遍历。\n假设当前 memory-cgroup 结构为 root -\u003e A -\u003e B -\u003e C，当线程在 C 内分配了内存，那么内核在更新 C 的同时，它也会标记 B, A, root 为待更新状态； 当有线程需要读取 C 状态时，那么读取侧需要将 B, A, root 也更新了，才能保证 root -\u003e A -\u003e B -\u003e C 链路上的数据是一致的。 如果新增了 root -\u003e A -\u003e D -\u003e E memory cgroup, 但 D, E 没有数据的变化，那么在读取 C 的数据时，内核并不会遍历 D, E。 rstat 架构的选择性聚合优化了读取效率和准确性。关于 rstat 的更多细节可以查看 Linux Plumbers Conferences 2022 - cgroup rstat’s advanced adoption。\n脏页大小 - 18446744073709551614 ？ 回到 ETCD 遇到的这个问题上。 在更新 memory-cgroup 字段时，线程仅更新当前 CPU 的 memcg-\u003evm_stats_percpu-\u003estate 上，由读取侧调用 cgroup_rstat_flush_locked 函数来做 CPU 级别的数据聚合。\n那么问题来了，假设有 32 个 CPU，当 cgroup_rstat_flush_locked 读取第三个 CPU 上的数据时，第一个 CPU 产生了新的脏页，然后被第 30 个 CPU 刷盘了。 错过了第一个 CPU 产生的增量，导致在那个时刻的统计结果里脏页是负数。虽然状态最终是正确的，但负数被转化成 unsigned long 将变成非常大。\nstatic inline unsigned long memcg_page_state(struct mem_cgroup *memcg, int idx) { return READ_ONCE(memcg-\u003evmstats.state[idx]); } 根据前面提到的停顿时长计算公式，线程相当于无限期停服了。 好在内核允许的最大停顿时间为 200 ms，下一轮检查大概率就恢复正常了。 Revert “memcg: cleanup racy sum avoidance code PATCH 修复也非常简单，就是回滚之前的一个 PATCH。\n我在一个 CPU 32 vcores - Memory 64 GiB 虚拟机上复现了这个问题：\n* 单实例 ETCD 运行在 /sys/fs/cgroup/testing1 里，并使用 ETCD benchmark 疯狂发写请求 * 反复在 /sys/fs/cgroup/testing2 里运行 dd 来产生大量的脏页，迫使 ETCD 进程进入 balance_dirty_pages 通过 Tracing Event 日志发现，脏页大小为 18446744073709551614 (-2)。\n核数越多，越容易遇到这个问题。\n最后 博客停更好久了，有时间就多写写吧。\n","wordCount":"430","inLanguage":"en","datePublished":"2024-04-11T20:48:45+08:00","dateModified":"2024-04-11T20:48:45+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://fuweid.com/post/2024-dirtypage--2/"},"publisher":{"@type":"Organization","name":"fuweid","logo":{"@type":"ImageObject","url":"https://fuweid.com/favicon.jpg"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://fuweid.com/ accesskey=h title="fuweid.com (Alt + H)">fuweid.com</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://fuweid.com/>Home</a>&nbsp;»&nbsp;<a href=https://fuweid.com/post/>Posts</a></div><h1 class=post-title>脏页大小 - 18446744073709551614 ?!</h1><div class=post-description>etcd-io/etcd#17615</div><div class=post-meta>&lt;span title='2024-04-11 20:48:45 +0800 HKT'>April 11, 2024&lt;/span></div></header><div class=post-content><p>分享一个 <a href=https://github.com/etcd-io/etcd/issues/17615>etcd-io/etcd@17615</a> 问题：用户发现 etcd 进程写入 WAL 日志有抖动，但是磁盘压力并不大，而且 fsync 系统调用都很正常；
后来通过 Tracing 工具定位到了内核 memory-cgroup 脏页数据统计有问题，不过该问题仅会出现在 v5.15.0-63 小版本。
<a href=https://github.com/etcd-io/etcd/issues/17615#issuecomment-2017512594>17615</a> 问题单里有详尽的定位过程，推荐看看。
因为这个问题，我翻阅了相关的内核 PATCH 邮件，做了以下的脏页分配限流 (简单) 总结。</p><h2 id=脏页分配限流---balance_dirty_pages>脏页分配限流 - balance_dirty_pages<a hidden class=anchor aria-hidden=true href=#脏页分配限流---balance_dirty_pages>#</a></h2><p>回写 (Writeback) 是指内核负责将脏页 (DirtyPage) 刷入存储设备上，它涉及到脏页分配控制。</p><p>在 v4.2 版本之前，脏页分配更多是由 memory-cgroup 来控制；而脏页流控核心 - <a href=https://elixir.bootlin.com/linux/v5.15/source/mm/page-writeback.c#L1560>balance_dirty_pages</a> - 根据全局的脏页水位情况来决定是否需要控速。
在 <a href=https://lwn.net/Articles/648292/>LinuxCon Japan 2015 会议</a>上，内核开发者 Tejun Heo 认为，在没有感知到全局脏页水位的情况，memory-cgroup 无法对脏页进行有效的控制。
核心 balance_dirty_pages 函数通过 <code>vm.dirty[_background]_{ratio, bytes}</code> 参数来计算全局脏页的水位上限。
Tejun Heo 认为普通的 memory-cgroup 也应采用同样的方式来计算组内的脏页水位上限，而根组 memory-cgroup 只不过是退化到全局模式，当然全局脏页的水位优先级更高。</p><p><img loading=lazy src=/img/2024-dirtypage--2/stack.png alt=stack></p><blockquote><p>NOTE: <code>balance_dirty_pages_ratelimited</code> 会调用 <code>balance_dirty_pages</code>。</p></blockquote><p>在 <a href=https://lore.kernel.org/lkml/1420579582-8516-9-git-send-email-tj@kernel.org/>writeback: cgroup writeback support</a> PATCH 合并到 v4.2 之后，每个 memory-cgroup 都有独立的设备回写控制器 (bdi_writeback)，它用于执行回写操作。
回写控制器维护写入带宽 - <a href=https://elixir.bootlin.com/linux/v5.15/source/include/linux/backing-dev-defs.h#L136>dirty_ratelimit</a> - ，初始状态下为 100 MiB/s。假设当前脏页大小为 dirty 和同时有 N 个线程在写入，该线程需要等待的时长大约为</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>pause = dirty / (dirty_ratelimit / N)
</span></span></code></pre></div><p>在 <a href=https://lore.kernel.org/all/20110806094526.878435971@intel.com/>writeback: dirty rate control</a> PATCH 里，内核开发者 Wu Fengguang 给出了 <code>N = roundup_pow_of_two(1 + HZ / 8)</code> 的计算方法；
自 2011 年以来，内核一直在使用该方法计算 N。
让线程停顿是为了防止脏页增长过快。但如果整体可用内存水位状态良好，内核应该尽量避免不必要的停顿，因此脏页水位有三个状态 freerun, setpoint 和 limit。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>threshold = vm.dirty_ratio * total_available_memory 
</span></span><span class=line><span class=cl>background_threshold = vm.dirty_background_ratio * total_available_memory
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>* freerun = (threshold + background_threshold) / 2
</span></span><span class=line><span class=cl>* limit = threshold
</span></span><span class=line><span class=cl>* setpoint = (freerun + limit) / 2
</span></span></code></pre></div><p>当脏页水位线低于 freerun 时，那么线程并不需要停顿，内存允许脏页快速增长；当脏页水位高于 limit 时，内核将通过 sleep(pause) 来禁止线程写入新的脏页，内核需要通过回写来降低水位线到安全的位置。
为了更好地计算停顿时长，内核引入了线程级别的带宽概念 <code>task_ratelimit</code>: 利用水位状态 <code>pos_ratio</code> 来调节写入带宽。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>* pos_ratio(dirty) = 1.0 + ((setpoint - dirty) / (limit - setpoint) ) ^3 
</span></span><span class=line><span class=cl>* task_ratelimit(dirty) = dirty_ratelimit * pos_ratio(dirty)
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>* pause = dirty / (task_ratelimit / N)
</span></span></code></pre></div><p><img loading=lazy src=/img/2024-dirtypage--2/pos_ratio.png alt=pos_ratio></p><p>内核还会根据 IO 回写控制器的情况来微调 <code>pos_ratio</code>，尤其是在内存较大的机器上能充分利用内存优势，
通过维持较高的写入带宽来迅速降低脏页水位线，细节可以查询 <a href=https://lore.kernel.org/all/20110806094526.733282037@intel.com/>writeback: dirty position control</a> PATCH。</p><h2 id=memory-cgroup-脏页状态更新---rstat>memory-cgroup 脏页状态更新 - rstat<a hidden class=anchor aria-hidden=true href=#memory-cgroup-脏页状态更新---rstat>#</a></h2><p>当进程跑在非根组的 memory-cgroup 时，balance_dirty_pages 需要从对应 memory-cgroup 获取当前的脏页大小。</p><p>2019 年 <a href=https://lore.kernel.org/lkml/20190412151507.2769-4-hannes@cmpxchg.org/>mm: memcontrol: make cgroup stats and events query API explicitly local</a> PATCH 让内核在更新侧 (内存的分配和释放) 做 per-cpu 的批量数据聚合，减少读取侧因遍历 memory-cgroup 树形结构测带来的 CPU 消耗。
假设每次更新 32 个页的数据，在 32 CPU 下运行着 32 个 memory-cgroup，那么最大误差会在 128 MiB 左右。
为了解决误差和读取效率问题，内核开发者 Johannes Weiner 在 <a href=https://lore.kernel.org/linux-mm/20210202184746.119084-7-hannes@cmpxchg.org/>mm: memcontrol: switch to rstat</a> PATCH 里引入了 rstat 框架:
更新侧仅需为祖辈们维护 pending-update cgroup 队列，而读取侧仅选择性地做数据聚合，减少了不必要的遍历。</p><p>假设当前 memory-cgroup 结构为 <code>root -> A -> B -> C</code>，当线程在 C 内分配了内存，那么内核在更新 C 的同时，它也会标记 B, A, root 为待更新状态；
当有线程需要读取 C 状态时，那么读取侧需要将 B, A, root 也更新了，才能保证 <code>root -> A -> B -> C</code> 链路上的数据是一致的。
如果新增了 <code>root -> A -> D -> E</code> memory cgroup, 但 D, E 没有数据的变化，那么在读取 C 的数据时，内核并不会遍历 D, E。
rstat 架构的选择性聚合优化了读取效率和准确性。关于 rstat 的更多细节可以查看 <a href=https://lpc.events/event/16/contributions/1240/>Linux Plumbers Conferences 2022 - cgroup rstat&rsquo;s advanced adoption</a>。</p><h2 id=脏页大小---18446744073709551614->脏页大小 - 18446744073709551614 ？<a hidden class=anchor aria-hidden=true href=#脏页大小---18446744073709551614->#</a></h2><p>回到 ETCD 遇到的这个问题上。
在更新 memory-cgroup 字段时，线程仅更新当前 CPU 的 <code>memcg->vm_stats_percpu->state</code> 上，由读取侧调用 <a href=https://elixir.bootlin.com/linux/v5.15/source/kernel/cgroup/rstat.c#L148>cgroup_rstat_flush_locked</a> 函数来做 CPU 级别的数据聚合。</p><p><img loading=lazy src=/img/2024-dirtypage--2/cgroup_rstat_flush_locked.png alt=cgroup_rstat_flush_locked></p><p>那么问题来了，假设有 32 个 CPU，当 <code>cgroup_rstat_flush_locked</code> 读取第三个 CPU 上的数据时，第一个 CPU 产生了新的脏页，然后被第 30 个 CPU 刷盘了。
错过了第一个 CPU 产生的增量，导致在那个时刻的统计结果里脏页是负数。虽然状态最终是正确的，但负数被转化成 unsigned long 将变成非常大。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=k>static</span> <span class=kr>inline</span> <span class=kt>unsigned</span> <span class=kt>long</span> <span class=nf>memcg_page_state</span><span class=p>(</span><span class=k>struct</span> <span class=n>mem_cgroup</span> <span class=o>*</span><span class=n>memcg</span><span class=p>,</span> <span class=kt>int</span> <span class=n>idx</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=nf>READ_ONCE</span><span class=p>(</span><span class=n>memcg</span><span class=o>-&gt;</span><span class=n>vmstats</span><span class=p>.</span><span class=n>state</span><span class=p>[</span><span class=n>idx</span><span class=p>]);</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>根据前面提到的停顿时长计算公式，线程相当于无限期停服了。
好在内核允许的最大停顿时间为 200 ms，下一轮检查大概率就恢复正常了。
<a href=https://lore.kernel.org/all/20220817172139.3141101-1-shakeelb@google.com/>Revert &ldquo;memcg: cleanup racy sum avoidance code</a> PATCH 修复也非常简单，就是回滚之前的一个 PATCH。</p><p>我在一个 CPU 32 vcores - Memory 64 GiB 虚拟机上复现了这个问题：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>* 单实例 ETCD 运行在 /sys/fs/cgroup/testing1 里，并使用 ETCD benchmark 疯狂发写请求
</span></span><span class=line><span class=cl>* 反复在 /sys/fs/cgroup/testing2 里运行 dd 来产生大量的脏页，迫使 ETCD 进程进入 balance_dirty_pages
</span></span></code></pre></div><p>通过 Tracing Event 日志发现，脏页大小为 18446744073709551614 (-2)。</p><p><img loading=lazy src="/img/2024-dirtypage--2/dirtypage=-2.png" alt="dirtypage=-2"></p><p>核数越多，越容易遇到这个问题。</p><h2 id=最后>最后<a hidden class=anchor aria-hidden=true href=#最后>#</a></h2><p>博客停更好久了，有时间就多写写吧。</p></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=next href=https://fuweid.com/post/2023-08-sync-containerd-issue/><span class=title>Next »</span><br><span>同步近期 containerd 的高频问题</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://fuweid.com/>fuweid</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>